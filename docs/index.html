<!DOCTYPE html>
<html>
  <head>
    <title> An Inner perspective on Topological Data Analysis(TDA) </title>
    <script type="text/javascript"
	    src="latexit.js"></script>
    <script type="text/javascript">
      LatexIT.add('p',true);
    </script>
  </head>
  <body>
    <h1> An Inner perspective on Topological Data Analysis(TDA)</h1>
    <h2> Abstract </h2>
    <p> This manuscript investigates the influence of shape of the
    data on the persistent diagrams produced by TDA. This document
    also provides a brief outline on how TDA works in Mathematical
    sense. It also introduces the reader Mathematical concepts that
      are essential for understanding of TDA.</p>
    <h2> Mathematical Background </h2>
    <p> We here assume the reader is familiar with topological
    concepts such as Toplogical spaces, Topology,Homemorphisms,Open
    and Closed sets.</p>
    <h3> Fundamental Problem in Topology </h3>
    <! Bold the below line>
    <p> Are two topological space equivalent?</p>
    
    <p>The whole study of topology is to based on the above question.
    We need to find a homemorphisim between two given spaces to prove
    that there are equivalent, and this procedure is difficult.So, we
    try and show a relatively simpler problem that is to show that two
    spaces are not eqivalent we find topological invariants in both
    the spaces and if they are not equal then we conclude the space
    are not equivalent.One such topological invariant is called the
      Fundamental Group.</p>
    <h4>Homotopy of Paths </h4>
    <p> Let $(X,\tau)$ be a topological space. If $f,f^{'}$ are
    continuous maps from the space $X$ into $Y$, we say $f$ is
      homotopic to $f^{'}$ if there exist a continuous map
      $F:X \times [0,1] \rightarrow Y$
      such that $F(x,0)=f(x)$ and $F(x,1)=f^{'}(x)$ for each $x$.</p>

    <h4>Homotopy</h4>
    <p> Homotopy is the collection of continuous 1-parameter family of
    maps from $X \rightarrow Y$. As the parameter continuously changes
    from o to 1, the functions continuously deform from $f$ to
      $f'$.</p>
    <! Add a image here for homotopy >

    <h4> Path Homotopic </h4>
    <p>Two paths $f$ and $f'$ mapping $[0,1]$ into $X$ are said to be
    path homotopic if they have same initial point $x_{0}$ and same
      final point $x$ and if there is a cont map
      $F:[0,1] \times [0,1]\rightarrow X$ such that $F(s,0)=f(s)$,
      $F(s,1)=f'(s)$, $F(0,t)=x_{0}$ and $F(1,t)=X_{0}$ </p>

    <em> Homotopy and Path-Homotopy are equivalance relations. Hence
    they partition the space of paths into equivalance classes call it
    S. </em>

    <h4> Product of paths </h4>
    <p> $f$ is a path in $X$ from $x_{0} \rightarrow x_{1}$<br>
      $g$ is a path in $X$ from $x_{1} \rightarrow x_{2}$
      then the product $f*g$ is the path $h$ st
      <div lang="latex">
	h(s)=\begin{cases} 
      f(2s) & s \in [0,\frac{1}{2}] \\
      g(2s-1)& s\in [\frac{1}{2},1] \\
       \end{cases}
      </div> </p>

     <p>$h$ is continuous and well defined path from
       $x_{0} \rightarrow x_{2}$</p>

  <em> The equivalance classes S along with the product operation
    forms a Groupoid. </em>

   <p> It forms a groupoid instead of a group because, the product
   betwen two paths is always not defined. So to $S$ into a group we
   will set $x_{0} \in X$ as a base point and restrict all homotopic
   classes that start and end at the basepoint call it $G$. Now $G$ is
   group with the product operation. We call this group
   $G=\pi_{1}(X,x_{0})$ as the <strong>Fundamental group of
   $X$</strong> relative to the base point $x_{0}$</p>

   <h4> Properties of Fundamental group </h4>
   <! Fill in >
   <ul>
     <li> <p>If $X$ is path connected and $x_{0},x_{1}$ are two points
       of $X$ then $\pi_{1}(X,x_{0})$ is isomorphic to
	 $\pi_{1}(X,x_{1})$ </p></li>
     <li> Fundamental group is a topological invariant of the space
       X </li>
     <li> Fundamental group of two homeomorphic spaces are isomorphic
     but the converse does not hold </li>
     
     
   </ul>
<h3> Simplicial Complexes </h3>
<h4>Introduction</h4>
<p> Simplicial complexes are made of collection of
simplices(satisfying some properties), which are generalization of
triangles in k-dimensions. These simplices are basic building blocks
of topology which we will be constructing from the Data point in
higher dimension. Given any two spaces $X$ and $Y$ we can decompose
  them into simplices $\{X\}_{i},\{Y\}_{i}$ and any continuous map
  $f:X \rightarrow Y$ can be approximated by a linear map $f_{i}$ on each
simplex $i$. Moreover this approximating map $\sum_{i}f_{i} \equiv f$ ie, they belong to same homotopy class.</p>
<h4> Convex Independent </h4>
<p> A set $\{V_{0},V_{1},\dots,V_{k} \}$ of vectors in a vector space
  $V$ is convex independent if the set $\{V_{1}-V_{0},V_{2}-V_{0},\dots,V_{k}-V_{0} \}$ is linearly independent.</p>
<h4> Closed k-Simplex-[] </h4>
<p> Let $\{V_{0},V_{1},\dots,V_{k} \}$ be a convex independent set
then the smallest convex set containing $\{V_{0},V_{1},\dots,V_{k} \}$
  is called a close k-simplex of dimension k.</p>

<h4> Barycentric coordinates </h4>
    <p>If $v \in [V_{0},V_{1},\dots,V_{k}]$ a k-closed simplex then if
      $v=\sum_{i} a_{i} V_{i}$ then the coefficients $a_{i}$ with
      $a_{i} \geq 0,\sum_{i} a_{1} =1$ is called the barycentric
      coordinates.</p>

    <h4> Open simplex-() </h4>
    <p> Let $\{V_{0},V_{1},\dots,V_{k} \}$ be a convex independent
      set, the set
      $\{v \in [V_{0},V_{1},\dots,V_{k}],a_{i} > 0,i=1,2,\dots,k\}$
      is called the open simplex.</p>
    <h4> Simplicial Complex </h4>
   <p> A simplicial complex (K) is a finite set of open simplicies in
     some ${\rm I\!{R}^{n}$ such that
     <ol>
       <li> <p>If $(s) \in (K)$ then all open faces of $[S] \in (K)$ </li></p>
       <li> <p>If $(s_{1}),(s_{2}) \in K$ and $(s_{1}) \cap (s_{2}) \neq \phi $ then
	 $(s_{1})=(s_{2})$</li></p>
       </ol>
</p>

<! Add image of simplices 1,2,3 simplexes>
 <p> A k-simplex contains $k+1$ vertics </p>

    <h4> Sub Complex </h4>
<p> A sub complex of a simplicial complex(K) is a simplicial complex(L) st
  $(s) \in L \implies (s) \in K$ </p>

<h4> Simplicial Map </h4>
<p> Let $K$ and $L$ be two simplicial complexes. A map $\phi:[K] \rightarrow [L]$
  is a simplicial map if
  <ol>
       <li> <p>For each vertex $v \in K \implies \phi(v) \in L$ </li></p>
<li> <p>For each simplex $(v_{0},v_{1},\dots,v_{k}) \in K$ the vertices
    $(\phi(v_{0}),\phi(v_{1}),\dots,\phi(v_{k}))$ all lie in some closed
    simplex of $L$</li></p>
<li><p>For each $(s) \in K$ and $p=\sum_{i=0}^{k} a_{i}v_{i} \in (s)$
    the image of the point p is $\phi(p)=\sum_{i=0}^{k} a_{i} \phi(v_{i})$  </li></p>
       </ol>
</p>

<h3> Fundamental group of Simplicial complexes </h3>
<p> We first define a set of operation on structures of simplicial complex $K$</p> 
  <h5> Edge in K </h5>
<p>It is an ordered pair $e=(v_{1},v_{2})$ of vertices of $K$
  such that $v_{1},v_{2}$ lie in some simplex of $K$ </p>

  <h5> Route in K </h5>
<p>It is a finite sequence $w=e_{1}e_{2} \dots e_{k}$
  of edges in $K$ such that for each $i \in (1,2,\dots,k-1)$
  the end of $e_{i}=$ the origin of $e_{i+1}$ </p>

  <h5>Product of routes </h5>
<p>Let $\omega=e_{1}e_{2} \dots e_{k},\tau=e_{1}^{'}e_{2}^{'} \dots e_{k}^{'}$
  be routes such that end of $e_{k}=$ origin of $e_{1}^{'}$
  then $\omega * \tau =e_{1}e_{2} \dots e_{k}e_{1}^{'}e_{2}^{'} \dots e_{k}^{'}$.</p>

  <h5> Inverse of a route </h5>
<p>If $\omega=e_{1}e_{2} \dots e_{k}$ then
  $\omega^{-1}=e_{k}^{-1}e_{k-1}^{-1} \dots e_{1}$  </p>

  <h5>Edge equivalence </h5>
<p>Let $e=(v_{1},v_{2}),f=(v_{2},v_{3})$ then $e*f$
  is edge equivalent to $(v_{1},v_{3})$</p>

<h4> Edge path Group </h4>

<p> Let $K$ be a simplicial complex, $v$ a vertex of $K$ and $E(k,v)$ be
the set of edge equivalent classes of routes in $K$ with origin $v$
and end $v$ then $E(k,v)$ is a group with identity $(v,v)$ under the
operation $*$ and inverse defined as above. This group is called the
  edge path group of $K$ at $v$.</p>

<p><em>Let $K$ be a simplicial complex and let $v_{0}$ be a vertex of
$K$ then $E(K,v_{0})$ is isomorphic with $\pi_{1}([K],v_{0})$ </em></p>

<h3> Homology theory </h3>

<h4> Simplicial Homology </h4>
<p> Let $S$ be a $l-$simplex with vertices $(v_{0},v_{1},\dots,v_{l})$
  consider two orderings $(v_{j_{1}},v_{j_{2}},\dots,v_{j_{l}})$ and
  $(v_{k_{1}},v_{k_{2}},\dots,v_{k_{l}})$ of the vertices they are equivalent
  if $(k_{1},k_{2},\dots,k_{l})$ is an even permutation of
  $(j_{1},j_{2},\dots,j_{l})$. This is a equivalence relation and it
  partitions the ordering of vertices $(v_{0},v_{1},\dots,v_{l})$
  into two equivalence classes.</p>
<h4> Oriented Simplex </h4>
<p> An oriented simplex is a simplex $S$ together with a choice of one
  of the equivalence classes denoted by $<v_{0},v_{1},\dots,v_{k}>$.</p>
<h4> Group of l-chains of K </h4>
<p>Let $K$ be a simplicial complex and $I$ Group of integers.<br>
  $C_{l}(K,l)=\frac{X}{Y}$ where,<br> $X$- Free group generated by all
  oriented simplices of $K$ <br> $Y$ is the subgroup generated by
  $(<v_{0},v_{1},\dots,v_{l}>+<v_{1},v_{0},v_{2},\dots,v_{l}>)$.
  <br> $C_{l}(K,l)$ is a abelian group and is called group of l-chains
  of K with integer coefficients.</p>


<h4> Boundary of the oriented simplex </h4>
<p> Let $ < s > = < v_{0},v_{1},\dots,v_{l+1}>$ be a $(l+1)$ oriented
      simplex. The boundary $\parial$ of $< s >$ is the $l-1$ chain
	defined by <br>
	$\partial =\sum_{j=0}^{l+1}(-1)^{j} < v_{0},v_{1},\dots,v_{j-1},v_{j+1},\dots,v_{l+1}>$ </p>


<h4>Boundary Map</h4>
<p> Let $K$ be a simplicial complex and let $G$ be an abelian group
  then the boundary map <br>
  $ \partial:C_{l+1}(K,G) \rightarrow C_{l}(K,G)$ <br> 
  is defined as
  <br>

  <!\partial(\sum g_{s} <s>) =\sum g_{s} \partial(s)>  <!Problem with this line>
  
Boundary of a boundary is $0$, ie the $\partial$ $^{2}=0$ </p>


<h4> Cycles an Boundaries</h4>
<p> Given a simplicial complex $K$ and a abelian group $G$ let
  <br>
  $Z_{l}(K,G)={c \in C_{l}| \partial(c) =0}$ <br>
  all elements of $Z_{l}$ are called cycles
  <br>
  $B_{l}(K,G)={\partial(c)|c \in C_{l+1}(K,G)}$ <br>
  such $\partial (c)$ are called boundaries </p>
</p>

<h4> Homology Group </h4>
<p> We define the $l^{th}$ homology group as
  $H_{l}(K,G)=\frac{Z_{l}(K,G)}{B_{l}(K,G)}$</p>

<h4> Betti numbers </h4>
<p> We define the $l^{th}$ betti number $\beta_{l}$ of $K$ is the integer defined as
  $\beta_{l}=dim(H_{l(K,G)})$ <br>
  Here in TDA we will work with $G=Z_{2}$ and
  <ul>
    <li> <p> $\beta_{0}$ denotes the number of connected components </p> </li> 
    <li> <p>$\beta_{1}$ denotes the number of 1 dimensional holes </p> </li> 
    <li> <p>$\beta_{2}$ denotes the number of 2 dimensional holes </p> </li> 
  </ul>
  
</p>

<h2> Introduction to TDA </h3>
<p> TDA stands for topological data analysis, where we use topological
methods to analyse the data. Analysis of topological aspects of the
data provide a breif insight into the properties of the system. Since
Higher dimension data cannot be visuvalized directly we apply
techniques such as these to infer about the topological aspects of it,
such as number of connected components or number of n dimensional
holes. TDA is not only used to infer topological aspects of the Data,
but it is also used as a tool in cluster analysis and lot more. We
will try and explore all of these here. TDA uses persistent homology
techinques to create topology out of the data and calculate its betti
  numbers.</p>

<p> So how is a topology made out of a set of datapoints? TDA has
  mainly two methods to approach this problem
  <ul>
    <li> <strong>Topology using functions </strong> In this method,
    TDA creates a new grid or mesh of data points within the
    appropriate range of the input data and then for each point on the
    grid TDA evaluvates user specified functions taking the input data
      as input. Most commonly used functions are
      <ol>
	<li> Distance function (L2 Norm) </li>
	<li> Distance to measure Function </li>
	<li> k Nearest Neighbours </li>
	<li> Kernel Density estimate </li>
	<li> Kernel Distance estimate </li>
      </ol>
      more about the above functions will be elaborated in the
      following sections. The resulting output is a surface</li>
    <li> <strong> Vectoris rips complex </strong> <p> In this method
    we create a vectoris rips complex $R(X,\epsilon)$ by varying
    $\epsilon$ over user specified range and $X$ denotes the
    data.$R(X,\epsilon)$ consist of simplices with vertex in $X$ and
    diameter atmost $\epsilon$. $\sigma$ is included in a simplicial
    complex $K$ if each pair of the vertices in $\sigma$ are atmost
    $\epsilon$ distance apart. For each epsilon we get
    different topological spaces.</p></li> 
  </ul>
</p>
<h3> Filtration and Persistent Homology </h3>
<p>Filtration is a set on increasing simplicial complex such that
  $\phi = K_{0} \subseteq K_{1} \subseteq \dots \subseteq K_{n}=K$
  where $\phi$ is the filtration and $K$ is the simplicial complex.
  TDA creates the filtration in two different ways based on which type
  of method was used to create the topology
  <ul>
    <li> <p> By creating a sublevel set with parameter $a$ and varying
    the parameter $a$ will give different simplicial complexes which
	will form the filtration </p></li>
    <li> <p> By varing $\epsilon$ in rips complex will give rise to
	rips filtration</p></li>
  </ul>
  <p> We are interested in the topological evolution of topological
  charateristics of the data. Now,to quantify the evolution of the
  topological charateristics we calculate the $l^{th}$ betti number
  $\beta_{l}$ for all simplexes in the filtration. From this we see
  which features(ie, $\beta_{l}$)of the data persisted for a longer
  time over the filtraion. We then define birth of a feature(ie,
  connected component or a 1-dim hole ..etc) that is the first time
  the feature appears and death of the feature is the first time the
  feature disappers as we transverse through the
  filtration. Persistent diagram is the plot between birth time and
  death time with each point representing a feature. Anything that is
  on the $45$ degree line is considered to be error because it
  represents the features that persisted for smaller time interval.
  We search for features that are far away from this $45$ degree lines
  in the persistent diagram.</p>
</p>
<h3> Example </h3>
<img src="im1_1.jpg" alt="eg1" width="700" height="900">
<img src="im1_2.jpg" alt="eg2" width="700" height="600">
<h3> Effect of shape on persistent diagrams </h3>

<p>We aim to see how structure of the dataset is reflected in
persistent diagrams. Hence we approach this problem by simulating
different set of data and plotting persistent diagrams for each of
these. The left plots(X vs Y) represents the simulated dataset and the
rightplots(Birth Vs Death) represent the persistent diagrams. Each
  point in the persistent diagram represents a connected component.</p>
<figure>
  <img src="output_2.gif" alt="1" style="width:600px;height:400px;">
  <figcaption>Plot:1</figcaption>
</figure>

<figure>
<img src="output_3.gif" alt="2" style="width:600px;height:400px;">
  <figcaption>Plot:2</figcaption>
</figure>

<figure>
<img src="output_5.gif" alt="4" style="width:600px;height:400px;">
  <figcaption>Plot:3</figcaption>
</figure>

<figure>
<img src="output_4.gif" alt="3" style="width:600px;height:400px;">
  <figcaption>Plot:4</figcaption>
</figure>

<p> We used Vector Rips complex method along with Rips filtration to
plot these plots. We can from Plot:1 and Plot:2 that there are two
connected components which merge to one another to form a single
connected component. This feature is correctly represented in the
respective persistance diagrams by the points which move away from the
$45$ degree line and merge with the point above. Representing that
initially there were two connected components which merged to form
one. If you look at Plot:2 and Plot:3 we see that as the points
scatter that they move away from each other or as the resolution
decreases. We can see errors building up in the persistent diagram and
all these errors lie on the $45$ degree line representing that these
features lived only for short period and that it must be due to lack
of resolution. </p>
  
<h3> Application of TDA on Diabetes dataset </h3>
<p> We set to apply the above method of analysis to a real world
dataset of diabetes, the aim was to figure out if the above algoritm
is able to classify ie, cluster out the diabetic and healthy
individuals. That is we expect to obsereve two connected components
one denoting the healthy and the other patients</p>
<h4> Description of the Dataset </h4>
<p>The data consist of "GSH" and "HbA1c" as features and 100
individuals for whom the feature values have been measured. Out of
this 100 there are 49 healthy individuals or controls and 51 diabetic
partients. The following diagram was plotted after z-scoring the data
<figure>
<img src="data.png" alt="data" style="width:600px;height:400px;">
  <figcaption>Plot:Red dots representing the Diabetic and Black
  representing the controls</figcaption>
</figure>
As we can see two clusters in the above plot(Diabetic and Controls),
we expect TDA to pick out these structures. Analysing the above
mentioned data using the RIPS Filtration method yeilds the following
plot
<figure>
<img src="persistance_rips.png" alt="persistance" style="width:600px;height:400px;">
  <figcaption>Plot:Persistance diagram of the diabetic dataset using
  rips filtration, the black dots denoting connected components and
  triangle denoting 1-dimensional holes. </figcaption>
</figure>
But, from the above plot we can see that TDA is picking out three
connected components or clusters, implying that there is one more
subclass of the individuals that we might have overlooked. Hence
analysis of TDA on the above dataset implies that there might exist
one more subgroup of the population other than controls and
diabetic.</p>
<h3> Density Clustering </h3>
<p> Density clustering is a part of the TDA package. It is a
clustering algorithm which works based on density estimates of the
dataset. Here we will use density clustering method from the TDA
package on the above mentioned Diabeties dataset to reinforce the our
hypothesis of a new subtype or subgroup of the population.</p>

<h4> Introduction to Density Clustering </h4>
<p> Let $X_{n}={x_{1},x_{2},\dots,x_{n}}$ be the samples from a
  unknown distribution $P$ on $R^{d}$ with each $x_{i}$ independent.
  Let $f$ denote the probability distribution of $P$ and let
  $A \subset R^{d}$ then the probability of observing data points
  $X_{n}={x_{1},x_{2},\dots,x_{n}}$ inside $A$ is
  $P(A)=\integral_{x \in A}f(x)dx$, where the integral is lebegue integral.</p>

<p> Now we define clusters as the regions of high density
ie,probability seperated by regions of low density. Now, we define a
level set $L_{f}(\lambda)=cl{x \in R^{d}|f(x) \geq\lambda}$.
$L_{f}(\lambda)$ is a set in $R^{d}$ with each point in the set having
density greater than $\lambda$. Any d-dimensional subset of
$L_{f}(\lambda)$ is called a <strong>high density region</strong>.
Maximal connected subset of $L_{f}(\lambda)$ is called a <strong> High
density cluster of P</strong>. Now as we vary the $\lamba$ from $0$ to
$\infty$, we record the evolution of high density clusters of P. This
creates a cluster density tree of P. $T={$L_{f}(\lambda)$|\lamba \geq 0}$.
This $T$ is called a tree and it satisfies </p>
<figure>
<img src="level.png" alt="level_set" style="width:600px;height:400px;">
  <figcaption>Plot:Formation of a lambda tree from a given probability
  distribution function. </figcaption>
</figure>
<ul>
    <li> <p> If $A,B \in T$ then $A \subset B$ or $B \subset A$ or $A \intersect B = \phi$ </p> </li>
  </ul>
<p> This tree is called the $\lamba$ tree, simillarly we can define
  $\alpha$ index tree and $\kappa$ index tree. We applied the above
  described method to the above described diabetes dataset and we
  found that density clustering algorithm supports our claim.</p>
<figure>
<img src="lambda.png" alt="lamba tree" style="width:600px;height:400px;">
  <figcaption>Plot:Lambda tree for the diabetes dataset. </figcaption>
  <img src="cluster.png" alt="cluster" style="width:600px;height:400px;">
  <figcaption>Plot: We can see 3 clusters using the above mentioned method. </figcaption>
</figure>

<h2> The Mapper algorithm and DSGA Analysis (Post Midsem) </h2>
<h3> Introduction </h3>
<p> We here try to understand the workings and inner aspects of the
  famous Mapper algorithm. Mapper is a part of the TDA toolkit. We
  here read a paper
  <a href="https://www.ncbi.nlm.nih.gov/pubmed/21482760"> Topology
  based data analysis identifies a subgroup of breast cancers with a
  unique mutational profile and excellent survival.</a> to understand
  how they used mapper and DSGA to identify a subgroup of patients.</p>
<p> Mostly all computational part of the data analysis ultimately
identifies the shape charateristic of the data eg: Clustering
algorithms looks for clusters which are shape charateristic of the
data..etc. Hence shape recogonizion of a dataset in high dimension is
highly crucial for analysis. In this paper they describe a method
called <strong> Progression Analysis of Disease(PAD) </strong>, the
  following are the advantages of this method
  <ul>
    <li> The clustering done by PAD is robust </li>
    <li> It provides biologically meaningful shape charateristics </li>
    <li> It is also a visuvalization tool </li>
    <li> PAD is not too much distance/metric sensitive as PCA and MDS(Multi Dimensional Scaling) </li>
  </ul>

The rest of the paper sheds more light on this PAD algorithm and how
it identified the new "c-MYB" breast cancer subgroup of the
population.  PAD is a combination of Mapper and DSGA(Disease Specific
Genome analysis).</p>

<h3>DSGA(Disease Specific Genome Analysis) </h3>
<p> DSGA is a genome analysis technique that employs comparision to
normal expression to extract data that is closely related with the
disease. DSGA is used to analyse gene expression datasets of healthy
and diseased individuals which are retrived from analysis of
microarrays. The microarray dataset contains intensity values for each
gene representing the expression level of that particular gene in the
genome sequence, for example </p>
<div lang='latex'>
  \begin{array}{|cccc|}
  gene & person1 & person2 & \dots \\
  gene1 & 1 & 50 & \dots \\
  gene2 & 10 & 24 & \dots \\
  \vdots & \vdots & \vdots & \dots \\
  \end{array} 
</div>

<p>DSGA tranforms the above array into two sums "Normal Component" $+$
"Diseased Component", where the normal component mimics the
normal/healthy tissue gene expression. It <strong>assumes</strong>
that mathematical model for normal expression is a linear subspace
which is derived from normal tissue gene expression.<br> This
assumption is crucial. This assumption is valid in biological setting
only for specific diseases/tissues. For example
consider <em>Cancer</em> where tumors are devoloped in tissues. These
tumors are due to overexpression or underexpression of specific genes
which are related to cancer. Hence the ratio of these cancer genes are
different in the cancer patients and healthy individuals. Hence, if we
consider gene expression of each individual as a vector
$V=(gene1,gene2,\dots)$ then there exist atleast one coordinate $i$
where the $gene_{i}$ is overexpressed or underexpressed in cancerous
than healthy individual. $V$ of healthy individuals should span a
linear subpace, because if we somehow minimize the unique
charateristic of that sample or individual then the ratios of genes
$\frac{g_{i}}{g_{j}}$ of healthy individuals should be
comparable. Hence we assume that normal expression data forms a linear
subspace. We then define the diseased components as deviations from
this linear subspace, ie residuals from this linear model. DSGA is
done in two steps one being creating this normal/healthy linear
subspace and projecting the array(to analyse) on this space</p>

<h4> Creation of Subspace </h4>
<p> To obtain a good approximation of normal expression data we first
reduce its dimension using a modified verison of PCA and then create a
linear subspace by taking span of it.<br> Let
$(T_{1},T_{2},\dots,T_{s})$ denote diseased tissue data and
$(N_{1},N_{2},\dots,N_{r})$ denote normal/healthy tissue data. Let
$v=(g_{1},g_{2},\dots,g_{\gamma})$ denote the gene expression vector
  and $v \in R^{\gamma}$.<br>
  Then $\mathcal{N}_{all}=<N_{1},N_{2},\dots,N_{r}> \subset R^{\gamma}$ as a subspace.
    Where $\mathcal{N}_{all}=\{v|v=\sum_{j} \alpha_{j} N_{j}, \alpha_{j} \in R \}$ <br><br>
    We need to construct $\mathcal{N}$ such that <br><br>
    $\mathcal{N} \subset N_{all}$ as a subspace <br>
    To do this we apply two steps</p>
    <ul>
      <li> FLAT Construction </li>
      <li> PCA </li>
    </ul>
  <p>To minimize the impact of the data charateristics that are unique
    to an individual or tissue sample we apply FLAT Construction.<br>
    Given $\{ N_{1},N_{2},\dots,N_{r} \}$ We define $\hat{N}_{i}$(flat
    vector) as the "least square fit" of the linear model
    $\sum_{j \neq i}^{r} \beta_{j} N_{j}$ with $0$ intercept.  We do this for
    each and every N to create $\{ \hat{N}_{1},\hat{N}_{2},\dots,\hat_{N}_{r} \}$.<br> We now apply
    PCA on these Flat constructed vectors to reduce its dimension say to $l$, which is a
    parameter in our model. Now we define $\mathcal{N}=< \hat{N}_{1},\hat{N}_{2},\dots,\hat_{N}_{l} >$
      This will act as our normal linear subspace.</p>
  <h4> Projection </h4>
<p> We define array space $A=< T_{1},T_{2},\dots,T_{s},N_{1},\dots,N_{r} >$.
    Since $\mathcal{N} \subset N_{all} \subset A$. We can write <br>
    $A=\mathcal{N} \oplus \mathcal{N}^{\perp}$, where $\mathcal{N}^{\perp}$
    is the orthogonal complement. Hence we can write any vector $v \in A$ as
    $v=v_{\mathcal{N}} \oplus v_{\mathcal{N}^{\perp}}$. This decomposition
    only depends on subspace $\mathcal{N}$ and not on the choice of basis.
    We define projection matrix $P=A(A^{t}A)^{-1}A^{t}$, hence any vector
    $v$ can be decomposed by using the following formula <br>
    $v_{\mathcal{N}}=P.v$ <br>
    $v_{\mathcal{N}^{\perp}}=v-v_{\mathcal{N}}$<br>
    We now will project all the data $v \in A$ into $v_{\mathcal{N}^{\perp}}$
    and use them for further analysis.</p>
<h3> The Mapper Algorithm </h3>
<p> It is a computational method for extracting simple descriptions of
high dimensional datasets in the form of simplicial complexes. This
method is a part of the TDA suite. Let us suppose we have a dataset
$X$ and a real valued function $f:X \rightarrow \mathbb{R}$, which
reflects the geometric aspects of the dataset or the property being
studied by the user,eg: Density estimator..etc. The target space
$\mathbb{R}$ is variable upon need to higher dimensional spaces or
manifolds, producing higher dimensional complexes or graphs with
  cycles.</p>
<h4> Topological background </h4>
<h5> Covering of a space </h5>
<p>If the set $X$ is a topological space, then a cover $\mathcal{C}$
of $X$ is a collection of subsets $U_{\alpha}$ of $X$ whose union is
the whole space $X$, where $\alpha \in \mathcal{A}$ and $\mathcal{A}$
is the index set.</p>
<h5> Nerve of a Covering</h5>
<p> Given a finite covering $U=\{U_{\alpha}\}_{\alpha \in \mathcal{A}$
of a space $X$. We define the nerve of a covering $U$ to be the
simplicial complex $N(U)$ whose vertex set is the indexing set
  $\mathcal{A}$, and where a family $\{ \alpha_{0},\alpha_{1},\dots,\alpha_{k} \}$
  spans a $k$-simplex if and only if
  $U_{\alpha_{0}} \cap U_{\alpha_{1}} \cap \dots \cap U_{\alpha_{k}} \neq \phi$
  [ie, in 0-dimension there is an edge between two vertices $\alpha_{i}$ and $\alpha_{j} \iff U_{\alpha_{i}} \cap U_{\alpha_{j}}$]</p>
<h5> Partition of Unity </h5>
<p> Partition of unity on $X$ is a collection ${g_{i}}$ of continuous
  real-valued functions on $X$ such that
  <ul>
    <li> <p> $g_{i} \geq 0$ for each $i$ </p> </li>
    <li> <p> Every $x \in X$ has a neighbourhood $U$ such that $U \cap supp(g_{i}) = \phi$ for all but finitely many $g_{i}$ </p> </li>
    <li> <p> For each $x \in X$, $\sum_{i} g_{i}(x)=1$ </p> </li>
  </ul>
</p>
<h5> Subordinate to an open cover </h5>
<p> Partition to unity ${g_{i}}$ on $X$ is a subordinate to an open cover of $X \iff$ for each $g_{i} \exists$ an element $U$ of the cover such
  that $supp(g_{i}) \subset U$ where $supp(g_{i})=\overline{\{x \in X | g_{i}(x) \neq 0 \}}$</p>
  </br>
<h4> The theory of mapper </h4>
  <p> If ${v_{0},v_{1},\dots,v_{k}}$ are the vertices of simplex, we
    can define barycentric coordinates for any point inside the
    simplex.  For any point $x \in X$, we let $\tau(x) \subset A$ be
    the set of $\alpha \in A$ such that $x \in U_{\alpha}$ where
    ${U_{\alpha}$ is a finite covering}. Define $\rho(x) \in N(U)$ to be
    the point in simplex spanned by the vertices $\alpha \in \tau(x)$,
    whose barycentric coordinates are $(\phi_{\alpha_{0}},\phi_{\alpha_{1}},\dots,\phi_{alpha_{l}})$
    and $\{ \alpha_{0},\alpha_{1},\dots,\alpha_{l} \}$ is the enumeration of $\tau(x)$.
    $\rho$ is continuous and kind of provides partial coordination of
    $X$.</br>  Suppose we are given a space $X$ equipped with a
    continuous map $f: X \rightarrow Z$ where $Z$ is parameter space
    and if $Z$ is equipped with a covering
    $U=\{ U_{\alpha} \}_{\alpha \in A}$ for some finite indexing set $A$.
    </br>
    $f^{-1}(U_{\aplha})$ will also form an open covering of $X$. Since $f$ is continuous.
    Now for each $\alpha$, consider $f^{-1}(U_{\alpha}) \subset X$.</br>
    We can decompose </br>
    $f^{-1}(U_{\alpha})=\cup_{i=1}^{j_{\alpha}} V(\alpha,i)$ into its path connected components, </br>
    where $j_{\alpha}$ is the number of connected components. We call this covering obtained from $U$ as $\bar{U}$. </p>
  <h5> Map of coverings </h5>
<p> Let $U=\{ U_{\alpha}\}_{\alpha \in A}$ and $\gamma =\{V_{\beta}\}_{\beta \in B}$
  be two coverings of the space $X$ a "map
  of coveings" from $U$ to $\gamma$ is a function $f: A \rightarrow B$
  such that for all $\alpha on A$ we have
  $U_{\alpha} \subset V_{f(\alpha) \in B}$ 
</br>
Suppose we are given a map of coverings from $U$ to $\gamma$
ie, a map of sets $f:A \rightarrow B$ satisfying the above conditions
it induces a map on simplicial complexes.
$N(f):N(U) \rightarrow N(\gamma)$
Suppose we have a family of coverings $\{U_{i}\}$ and maps of coverings
$f_{i}:U_{i} \rightarrow U_{i+1}$ then we obtain a diagram of simplicial
complexes and maps. </br>
$N(U_{0}) \xrightarrow{N(f_{0})} N(U_{1}) \xrightarrow{N(f_{1})} \dots \xrightarrow{N(f_{n+1})} N(U_{n})$.

Consider the space $X$ equipped with $f:X \rightarrow Z$ where $Z$ is the parameter space with
the covering $U$ and $\gamma$ and if we are given the map of covering $g:U \rightarrow \gamma$
of the space $Z$ then there is a corresponding covering $\bar{g}:\bar{U} \rightarrow \bar{\gamma}$ of space $X$.
ie, If $U \subset V$ then $f^{-1}(U) \subset f^{-1}(V)$ and $\bar{g}:\bar{u} \rightarrow \bar{\gamma}$ is such
that $U_{\alpha}(i) \subset V_{f(\beta)(j)}$. This is the main core concept of the mapper algorithm taking the
inverse of the covering and forming a simplicial complex out of it. Lets see some examples of how mapper
works below </p>
</br>
<em> <h4> Example 1 </h4> </em>    
<p> Consider the situation where X is $[-M,M] \subset \mathbb{R}$, the parameter space $[0,\infty)$
  and the function $f: X \rightarrow \mathbb{R}$ is the probability density function for a gaussian
  distribution given by $f(x)=\frac{1}{\sigma \sqrt(2 \pi)}e^{-\frac{-x^{2}}{2 \sigma^{2}}}$. The covering
  $U$ of $Z$ consists of 4 subsets $\{[0,5),(4,10),(9,15),(14,\infinity)\}$. We can see that $f^{-1}([0,5))$
  consists of two components colored blue in the diagram and
  $f^{-1}(14,\infty)$  consists of 1 connected component colored green.Simillarly one can do this inverse mapping of
  open sets in the open cover $U$ and create simplicial complex correspondingly by adding edges between
  the nodes if the inverse image overlaps.
  <figure>
  <img src="X.png" alt="X" style="width:250px;height:80px;">
  <img src="Z.png" alt="Z" style="width:600px;height:80px;">
   <figcaption>Fig: Left hand side is the X space and right is the Z
   space with open sets.Each open set is colored with one single
     color. </figcaption>
   <figure>
     <img src="normal.png" alt="distribution" style="width:600px;height:500px;">
   </figure>
   The final complex looks something like this, the color indicates the average
   value of the function on that cluster. The size of the node indicates the
   number of data points in that cluster.</p>
   <img src="simpl.jpg" alt="complex" style="width:250px;height:100px;">

   <em> <h4> Example 2 </h4> </em>
<p> Until the previous example we were working with a topological space which is continous
  but real world data isn't continuous hence there is no appropriate meaning to path
  connected component in discrete data. In order to replace this with an appropriate
  version we use clustering as a technique to replace the continum version path connectedness.
  Here is an example in this example we implement a python code for this algorithm/processes
  described above. Here is what the dataset looks like
  <img src="make_circles.png" alt="circle" style="width:600px;height:600px;"> </br>
  The code can be found  <a href="https://github.com/Jayanth-kumar5566/TDA/blob/master/Codes/make_circle.py">here</a>. </br> 
  The output of the code can be found <a href="make_circles_output.html">here</a>.

  Here we used the SUM of $x+y$ as the filter function </p>

  
  
</body>
  </html>
